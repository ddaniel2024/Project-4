{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "091acf33-0e8d-4955-bc95-244f04fdd426",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m col, when\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringIndexer, VectorAssembler\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Employee Attrition Prediction\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"C:\\\\Users\\\\admin\\\\Desktop\\\\2024\\\\Data-Analyst\\\\Assignments\\\\Projects\\\\last project 4\\\\Project-4\\\\Resources\\\\employee_attrition.csv\"\n",
    "data = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Display schema\n",
    "data.printSchema()\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = [\"EmployeeCount\", \"EmployeeNumber\", \"Over18\", \"StandardHours\", \"DailyRate\", \"HourlyRate\", \"MonthlyRate\"]\n",
    "data = data.drop(*columns_to_drop)\n",
    "\n",
    "# Encode categorical variables and assemble features\n",
    "categorical_cols = [field for (field, dtype) in data.dtypes if dtype == \"string\" and field != \"Attrition\"]\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column + \"_index\") for column in categorical_cols]\n",
    "assembler = VectorAssembler(inputCols=[column + \"_index\" for column in categorical_cols] + [field for (field, dtype) in data.dtypes if dtype == \"int\" or dtype == \"double\"], outputCol=\"features\")\n",
    "label_indexer = StringIndexer(inputCol=\"Attrition\", outputCol=\"label\")\n",
    "\n",
    "# Pipeline for feature transformation\n",
    "pipeline = Pipeline(stages=indexers + [label_indexer, assembler])\n",
    "data_transformed = pipeline.fit(data).transform(data)\n",
    "\n",
    "# Select features and label\n",
    "data_transformed = data_transformed.select(\"features\", \"label\")\n",
    "\n",
    "# Split data into training and test sets\n",
    "train_data, test_data = data_transformed.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "lr = LogisticRegression(maxIter=1000)\n",
    "\n",
    "# Train model\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions = lr_model.transform(test_data)\n",
    "\n",
    "# Evaluate model\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Display confusion matrix\n",
    "predictions.groupBy(\"label\", \"prediction\").count().show()\n",
    "\n",
    "# Save processed data to Parquet\n",
    "data_transformed.write.parquet(\"employee_attrition_processed.parquet\")\n",
    "\n",
    "# Load data from Parquet\n",
    "data_loaded = spark.read.parquet(\"employee_attrition_processed.parquet\")\n",
    "data_loaded.show()\n",
    "\n",
    "# Collect predictions for visualization\n",
    "preds = predictions.select(\"label\", \"prediction\").toPandas()\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = pd.crosstab(preds['label'], preds['prediction'], rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "\n",
    "# Plot confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fdc5ee-0dce-482a-b795-f164e443d8a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
